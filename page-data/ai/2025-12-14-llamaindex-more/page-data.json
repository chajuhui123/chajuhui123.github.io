{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai/2025-12-14-llamaindex-more/","result":{"data":{"site":{"siteMetadata":{"title":""}},"markdownRemark":{"id":"3a0f2507-663d-5969-9b7b-596224b456e8","excerpt":"LLM이 똑똑해지기 위해서는 단순히 모델 성능만 좋아서는 부족해요! AI…","html":"<p>LLM이 똑똑해지기 위해서는 단순히 모델 성능만 좋아서는 부족해요! AI가 필요한 정보를 잘 찾고, 맥락에 맞게 이해한 뒤, 적절한 행동까지 이어질 수 있도록 설계하는 것이 점점 더 중요해지고 있습니다.</p>\n<p>이 과정에서 핵심 역할을 하는 것이 <strong>바로 벡터 스토어, 텍스트 분할과 인덱싱, 그리고 RAG(Retrieval-Augmented Generation)</strong> 입니다.\n더 나아가 텍스트를 넘어 이미지까지 다루는 <strong>다중 모달 시스템</strong>, 그리고 답변을 넘어 목표를 완수하는 <strong>Agent RAG</strong>까지 등장하면서 AI 시스템의 구조는 점점 더 정교해지고 있어요.</p>\n<hr>\n<h2>1. 벡터스토어</h2>\n<blockquote>\n<p>벡터 스토어는 벡터화된 데이터를 효율적으로 저장하고 검색할 수 있도록 설계된 데이터 관리 시스템입니다.</p>\n</blockquote>\n<p><strong>LLM이나 검색시스템에서 벡터 스토어</strong></p>\n<ul>\n<li>텍스트, 이미지 또는 기타 데이터 → 벡터로 변환 → 유사도 계산하여 검색, 분석하는 작업이 자주 필요해요.</li>\n<li>벡터 저장소가 없다면? 데이터가 커질수록 검색 속도가 급격히 느려질 수 있어요.</li>\n</ul>\n<p><strong>임베딩 기반 라마인덱스 답변 생성</strong></p>\n<ul>\n<li>벡터 유사도를 기반으로 적절한 문서 검색이 가능해요.</li>\n<li>하지만 검색된 문서 바탕으로 자연어 형태의 답변을 생성하려면 추가적인 처리가 필요해요.</li>\n<li>라마인덱스, 크로마, 허깅페이스 임베딩 모델을 사용하여 임베딩 기반 답변 생성이 가능해요.\n<ul>\n<li>임베딩 모델을 별도로 지정하지 않으면 라마인덱스의 ChromaVectorStore 는 기본적으로 OpenAI의 text-embedding-ada-002 모델을 사용합니다. (이는 변경될 수 있어 공식 문서 참고 해야합니다!)</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2>2. 텍스트</h2>\n<p>라마인덱스에서 PDF, TXT, CSV, HWP … 등의 파일을 다룰 수 있어요. 전체적으로 로딩, 인덱싱, 쿼리 실행 등의 과정을 진행할 것이에요. 이를 알아보기 전, 다시 한 번 RAG 에 대해 정리해보아요.</p>\n<p><strong>Retrieval-Augmented Generation: AI에게 필요한 정보를 찾아오고, 찾아온 정보 기반으로 대답하게 만드는 기술</strong></p>\n<p>RAG은 기본적으로 아래 두 단계대로 동작해요.</p>\n<ol>\n<li><code class=\"language-text\">검색 단계(Retrieval-Augmented)</code>\n<ul>\n<li><strong>사용자의 질문과 관련된 문서를 검색하여 찾아오는 단계</strong></li>\n</ul>\n</li>\n<li><code class=\"language-text\">생성 단계(Generation)</code>\n<ul>\n<li><strong>찾아온 문서를 참고하여 답변 생성</strong></li>\n</ul>\n</li>\n</ol>\n<p>🤔 그런데 만약 찾고자하는 문서가 너무 길거나 방대한 양이라면 AI는?</p>\n<ul>\n<li>문서가 너무 길면 <strong>AI는 한 번에 읽을 수 없음. 토큰 길이 제한(예: 8k, 32k, 128k…)</strong></li>\n<li>많은 문서를 통째로 검색하면 <strong>속도가 느리고 정확도도 떨어짐</strong></li>\n<li>필요한 일부 정보만 추출하기 어려워 <strong>할루시네이션 위험이 증가</strong></li>\n</ul>\n<p>그래서 계속계속 등장하는 개념이 <code class=\"language-text\">텍스트 분할</code>과 <code class=\"language-text\">인덱싱</code> 이에요.</p>\n<p>청킹은 긴 문장을 짧게 나눠 노드에 담는 작업을 의미합니다. 잘 분할된 데이터는 RAG 답변 성능에 영향을 미치고, 답변 정확도 뿐만 아니라 속도에도 영향을 줍니다.</p>\n<ol>\n<li>토큰 단위 분할\n<ul>\n<li>하나의 청크는 단일한 의미를 담고 있어야 RAG의 성능이 좋아집니다.</li>\n<li>(장점) 길이가 균일해서 처리하기 쉬움</li>\n<li>(단점) 문장 중간이 잘려 <strong>의미 파악이 어려워 검색 품질이 나빠질 수 있음</strong></li>\n</ul>\n</li>\n<li>의미 단위 분할\n<ul>\n<li>임베딩 유사성을 기반으로 하나의 의미를 지닌 문장 단위를 찾아 분할하는 방식입니다.</li>\n<li>의미 분할 위치는 고정적이지 않고, 유동적으로 결정되기 때문에 상황에 따라 분할 후 노드의 길이와 노드의 총 개수가 다른 경우가 발생합니다.</li>\n<li>(장점) RAG 성능이 좋다.</li>\n<li>(단점) 구현이 어렵고 embedding 계산 비용이 높고 AI 판단하에 분할이기에 데이터 분할되는 부분이 항상 일치하지 않아서 노드의 길이와 갯수가 제각각</li>\n</ul>\n</li>\n<li>문장 단위 분할\n<ul>\n<li>문장의 경계를 존중하면서 텍스트를 분리하는 방식입니다.</li>\n<li>단락이끊겨서 주요 문장을 놓치는 경우도 발생합니다.</li>\n<li>(장점) 의미 흐름 유지</li>\n<li>(단점) 어떤 문장은 너무 길거나, 너무 짧을 수 있음</li>\n</ul>\n</li>\n</ol>\n<h2>2. 다중 모달 시스템</h2>\n<p>다중모달(Multi-Modality) 검색 시스템은 텍스트와 이미지 등 다양한 데이터 유형을 통합적으로 이해하고 검색할 수 있는 기술</p>\n<p>라마인덱스를 활용하면, <strong>텍스트와 이미지 데이터를 효과적으로 인덱싱</strong>, 이들 간의 <strong>의미적 연관성에 기반</strong>하여 정교한 검색을 수행할 수 있어요.</p>\n<p>Multi-Modality를 어떻게 고려할 수 있을까요? 크게 살펴보면 2가지 방법이 있다고 합니다.</p>\n<ol>\n<li>\n<p>여러 Modality를 하나의 벡터 공간에 Embedding 하기</p>\n<ul>\n<li>Multi-Modal 모델을 사용해서 이미지, 텍스트, 오디오 등 전부 제대로 된 의미를 갖는 벡터로 변환하여 임베딩. 사과를 먹는 그림과 ‘사과를 먹다’ 는 비슷한 벡터를 가지게 됩니다.</li>\n</ul>\n</li>\n<li>\n<p>여러 Modality를 하나의 Modality로 통합하기</p>\n<ul>\n<li>일반적으로 Text로 통합이 되며, 사과를 먹는 그림이 있다면, “한 사람이 사과를 먹고 있다.” 와 같은 캡션으로 바꿔 하나의 Modality로 통합합니다.</li>\n</ul>\n</li>\n</ol>\n<p>다중 모달 시스템을 구축할 때도 <code class=\"language-text\">데이터 수집 → 벡터 인덱싱 → RAG 시스템 구축</code> 로 진행할 수 있어요.</p>\n<hr>\n<h2>3. Agent RAG</h2>\n<p><strong>에이전트 RAG</strong>는 주어진 환경 관찰, 판단, 행동 → 특정 목표 달성하는 AI 시스템이에요. <strong>생각, 도구 선택, 도구 입력값, 도구 사용 결과</strong> 로 이어지는 추론 과정 시스템으로 이루어져요.</p>\n<p>챗봇과 에이전트 RAG 는 어떤 차이점이 존재할까요?</p>\n<p><strong>챗봇: 질문&#x26;답변으로 이루어짐.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">요청 : “휴가 관련해서 도와줘.”\n응답 : 규정을 설명해드릴까요? 아니면 휴가 신청 방법을 알려드릴까요?</code></pre></div>\n<p>이에 대한 답변에 대한 행동은 사용자가 직접합니다. 챗본은 물어보면 ‘대답’까지만, 실행은 사용자의 몫이에요.</p>\n<p><strong>AI 에이전트: 답을 넘어서 목표 달성을 위해 일을 처리</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">요청 : “휴가 관련해서 도와줘.”\n응답 : 원하는 휴가 날짜가 언제인가요?”\n    -> 사내 규정/RAG로 휴가 가능 일수 확인\n    -> 캘린더에서 일정 충돌 확인\n    -> 휴가 신청 폼 작성 초안 생성\n    -> 휴가신청서 확인받고 제출까지 진행</code></pre></div>\n<p>에이전트는 ‘목표를 끝까지 처리’하려고 스스로 단계들을 수행합니다.</p>\n<p><strong>ReAct 방법론이란?</strong></p>\n<blockquote>\n<p>개발 방법 중의 하나로 대규모 언어 모델이 추론과 행동을 결합하여 문제 해결하는 방법론</p>\n</blockquote>\n<p>생각(<code class=\"language-text\">Re</code>asoning)하면서 동시에 행동(<code class=\"language-text\">Act</code>ing)하도록 만드는 프롬프트/설계 방식이에요. 이름 그대로 <strong>Reason + Act</strong>를 합친 방법론으로써</p>\n<ol>\n<li>생각</li>\n<li>도구사용</li>\n<li>관찰</li>\n</ol>\n<p>세가지 과정을 반복하여 문제를 해결합니다!</p>\n<h2>🎁 정리</h2>\n<ul>\n<li>\n<p><code class=\"language-text\">벡터 스토어</code>는 임베딩된 데이터를 효율적으로 저장하고 유사도 기반 검색을 가능하게 하여, LLM과 검색 시스템의 성능과 확장성을 책임지는 핵심 요소입니다.</p>\n</li>\n<li>\n<p><code class=\"language-text\">RAG 시스템</code>은 검색 단계와 생성 단계를 분리하여, LLM이 신뢰할 수 있는 정보에 기반해 답변하도록 돕습니다.</p>\n</li>\n<li>\n<p><code class=\"language-text\">이때 텍스트 분할(청킹) 방식</code>은 검색 정확도와 응답 품질에 큰 영향을 주며, 토큰 단위, 문장 단위, 의미 단위 분할은 각각의 장단점을 가집니다.</p>\n</li>\n<li>\n<p><code class=\"language-text\">다중 모달 시스템</code>은 텍스트와 이미지 같은 다양한 데이터 타입을 통합적으로 이해하고 검색할 수 있도록 하며, 하나의 벡터 공간으로 통합하거나 텍스트로 변환하는 방식으로 구현할 수 있습니다.</p>\n</li>\n<li>\n<p><code class=\"language-text\">Agent RAG</code>는 단순히 답변을 제공하는 것을 넘어, 목표 달성을 위해 스스로 판단하고 도구를 사용하며 작업을 수행하는 AI 시스템입니다.</p>\n</li>\n<li>\n<p>이를 가능하게 하는 <code class=\"language-text\">ReAct 방법론</code>은 추론과 행동을 반복하며 문제를 해결하도록 설계된 접근 방식입니다.</p>\n</li>\n</ul>\n<p>결국, 좋은 AI 시스템은 <strong>“잘 찾고, 잘 이해하고, 잘 행동하는 구조”</strong> 위에서 만들어진다고 할 수 있습니다 ✨</p>","frontmatter":{"title":"LLM 서비스 만들기 전에 꼭 알아야 할 RAG 핵심 정리","category":"AI","date":"December 14, 2025","description":null,"draft":false}},"previous":{"fields":{"slug":"/ai/2025-11-03-llamaindex시작/"},"frontmatter":{"title":"라마인덱스 RAG 파이프라인"}},"next":null},"pageContext":{"id":"3a0f2507-663d-5969-9b7b-596224b456e8","previousPostId":"6e215895-2433-59a8-9890-be2778ca5146","nextPostId":null}},"staticQueryHashes":["2841359383","3274528899"]}